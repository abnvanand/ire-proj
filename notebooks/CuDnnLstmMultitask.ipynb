{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM Multitask.ipynb","provenance":[],"collapsed_sections":["JzH7PtlaPpBN"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"apoTJfS7Wa3U","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUNKZFJBWfVC","colab_type":"code","colab":{}},"source":["DATASET_PATH = \"/content/drive/My Drive/ire-proj/processedData\"\n","!ls \"$DATASET_PATH\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1E3dl4Aw8NK","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","\n","from keras import Sequential, Model, Input\n","from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Flatten, Dense, \\\n","                    GlobalAveragePooling1D, Dropout, LSTM, CuDNNLSTM, RNN, SimpleRNN, Conv2D, GlobalMaxPooling1D\n","from keras import callbacks\n","\n","import re\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Embedding\n","from keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder \n","import pickle\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.metrics import classification_report"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXRZjhyQPwnT","colab_type":"code","colab":{}},"source":["N_TRAINING_SAMPLES = None\n","\n","N_TEST_SAMPLES = N_TRAINING_SAMPLES // 2 if N_TRAINING_SAMPLES is not None else None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hQcYYZNlZx3z","colab_type":"code","colab":{}},"source":["def load_embeddings(word_index, embeddingsfile):\n","    embeddings_index = {}\n","    f = open(embeddingsfile, 'r', encoding='utf8')\n","    for line in f:\n","        #here we parse the data from the file\n","        values = line.split(' ') #split the line by spaces\n","        word = values[0] #each line starts with the word\n","        coefs = np.asarray(values[1:], dtype='float32') #the rest of the line is the vector\n","        embeddings_index[word] = coefs #put into embedding dictionary\n","    f.close()\n","\n","    print(f'Found {len(embeddings_index)} word vectors.')\n","\n","    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n","    for word, i in word_index.items():\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            # words not found in embedding index will be all-zeros.\n","            embedding_matrix[i] = embedding_vector\n","    \n","    embedding_layer = Embedding(len(word_index) + 1,\n","                                EMBEDDING_DIM,\n","                                weights=[embedding_matrix],\n","                                input_length=MAX_SEQUENCE_LENGTH,\n","                                trainable=False)\n","    return embedding_layer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EkzzVVf6Z-fd","colab_type":"code","colab":{}},"source":["MAX_NB_WORDS = 50000    #dictionary size\n","MAX_SEQUENCE_LENGTH = 1500  #max word length of each individual article\n","EMBEDDING_DIM = 300 #dimensionality of the embedding vector (50, 100, 200, 300)\n","tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~')\n","\n","TOKENIZER_DUMP_FILE='tokenizer.p'\n","\n","def tokenize_trainingdata(X):\n","    tokenizer.fit_on_texts(X)\n","    \n","    with open(TOKENIZER_DUMP_FILE, 'wb') as fp:\n","        pickle.dump(tokenizer, fp)\n","\n","    sequences = tokenizer.texts_to_sequences(X)\n","\n","    word_index = tokenizer.word_index\n","    print(f'Found {len(word_index)} unique tokens.')\n","\n","    X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","    return X, word_index\n","\n","def tokenize_testdata(X):\n","    with open(TOKENIZER_DUMP_FILE, 'rb') as fp:\n","        tokenizer=pickle.load(fp)\n","\n","    print(f'Found {len(tokenizer.word_index)} unique tokens.')\n","\n","    sequences = tokenizer.texts_to_sequences(X)\n","\n","    X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","    return X"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oYgT0kdTk4v7","colab_type":"code","colab":{}},"source":["def reverse_to_categorical(y):\n","    return np.argmax(y[:5], axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mbXNIWXRUvFY","colab_type":"text"},"source":["# Load datasets"]},{"cell_type":"code","metadata":{"id":"C5SNgt_R4gBr","colab_type":"code","colab":{}},"source":["df = pd.read_csv(filepath_or_buffer= DATASET_PATH + '/articles-training-bypublisher.csv',\n","                 names=['article_id', 'title', 'articleContent', 'bias', 'hyperpartisan'],\n","                 dtype={'title':str},\n","                 nrows=N_TRAINING_SAMPLES)\n","\n","df['title'] = df['title'].fillna(value=' ')\n","df.count()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YXlIpKD_FaZq","colab_type":"code","colab":{}},"source":["def perform_cleaning(text):\n","    text = text.lower().strip()\n","    text = ' '.join(e for e in text.split())\n","    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n","    return text\n","\n","df['title'] = df['title'].map(perform_cleaning)\n","df['articleContent'] = df['articleContent'].map(perform_cleaning)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CFJdEBdT_dv5","colab_type":"code","colab":{}},"source":["df.head()\n","# df.tail(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-w5jRnRPrEL","colab_type":"code","colab":{}},"source":["df_test = pd.read_csv(filepath_or_buffer=DATASET_PATH + '/articles-validation-bypublisher.csv',\n","                 names=['article_id', 'title', 'articleContent', 'bias', 'hyperpartisan'],\n","                 nrows=N_TEST_SAMPLES\n","                 )\n","df_test['title'] = df_test['title'].fillna(value=' ')\n","df_test.count()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dD8n2FOJQPhq","colab_type":"code","colab":{}},"source":["df_test['title'] = df_test['title'].map(perform_cleaning)\n","df_test['articleContent'] = df_test['articleContent'].map(perform_cleaning)\n","df_test.tail(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2JgTxNAt4j7s","colab_type":"code","colab":{}},"source":["print(df['hyperpartisan'].value_counts())\n","print(df_test['hyperpartisan'].value_counts())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JzH7PtlaPpBN","colab_type":"text"},"source":["# Define CNN model"]},{"cell_type":"code","metadata":{"id":"-huH-qQ8vEeJ","colab_type":"code","colab":{}},"source":["# def baseline_model(sequence_input, embedded_sequences, classes=2):\n","#     x = Conv1D(64, 5, activation='relu')(embedded_sequences)\n","#     x = MaxPooling1D(5)(x)\n","#     x = Conv1D(128, 3, activation='relu')(x)\n","#     x = MaxPooling1D(5)(x)\n","#     x = Conv1D(256, 2, activation='relu')(x)\n","#     x = GlobalAveragePooling1D()(x)\n","#     x = Dense(2048, activation='relu')(x)\n","#     x = Dropout(0.5)(x)\n","#     x = Dense(512, activation='relu')(x)\n","#     x = Dropout(0.5)(x)\n","#     preds = Dense(classes, activation='softmax')(x)\n","\n","#     model = Model(sequence_input, preds)\n","#     return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-GaGkqHvIma","colab_type":"code","colab":{}},"source":["# #put embedding layer into input of the model\n","# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","# embedded_sequences = embedding_layer(sequence_input)\n","\n","# model = baseline_model(sequence_input, embedded_sequences, classes=2)\n","\n","# model.compile(loss='categorical_crossentropy',\n","#               optimizer='adamax',\n","#               metrics=['acc'])\n","\n","# print(model.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WztjdKGq49kT","colab_type":"code","colab":{}},"source":["# model.fit(X_train, y_train,\n","#           validation_data=(X_validate, y_validate),\n","#           epochs=25, batch_size=64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mMYXLZbrUXIN","colab_type":"code","colab":{}},"source":["# y_pred = model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mklg0c4K6mPw","colab_type":"code","colab":{}},"source":["# y_pred = np.array([[1,0] if unbiased > biased else [0,1] for unbiased, biased in y_pred], dtype='float32')\n","# y_pred[:5]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AsEvUeuIAR1A","colab_type":"code","colab":{}},"source":["# accuracy_score(y_pred, y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iR-H2ZJptg-i","colab_type":"code","colab":{}},"source":["# model.save('cnn.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oLb1DF57PmNb","colab_type":"text"},"source":["# Define LSTM model"]},{"cell_type":"code","metadata":{"id":"wunr22dMoGGq","colab_type":"code","colab":{}},"source":["def LSTM_model(sequence_input, embedded_sequences, classes=2):\n","    x = CuDNNLSTM(32,\n","                  return_sequences=True)(embedded_sequences)\n","    x = CuDNNLSTM(64,\n","                  return_sequences=True)(x)\n","    x = CuDNNLSTM(128)(x)\n","    x = Dense(4096,\n","              activation='relu')(x)\n","    x = Dense(1024,\n","              activation='relu')(x)\n","    preds = Dense(classes,\n","              activation='softmax')(x)\n","\n","    model = Model(sequence_input, preds)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dwq0eV4tVUHQ","colab_type":"text"},"source":["# Binary classifier (Biased / Unbiased)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SjppIvA1bMYF"},"source":["## Separate labels from features"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3wED1DTtbMYM","colab":{}},"source":["X = df.articleContent.values\n","y_bias = df.hyperpartisan.values\n","y_bias_kind = df.bias.values\n","\n","X_test = df_test.articleContent.values\n","y_test_bias = df_test.hyperpartisan.values\n","y_test_bias_kind = df_test.bias.values\n","\n","NUM_CLASSES_BIAS = len(np.unique(y_bias))\n","NUM_CLASSES_BIAS_KIND = len(np.unique(y_bias_kind))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nRJiV-XXbMYY","colab":{}},"source":["print(y_bias[:5])\n","print(y_bias_kind[:5])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MCALMavEaeA6","colab_type":"text"},"source":["## Tokenize data"]},{"cell_type":"code","metadata":{"id":"gSq4NaWO5UFK","colab_type":"code","colab":{}},"source":["X, word_index = tokenize_trainingdata(X)\n","y_bias = to_categorical(y_bias, num_classes=NUM_CLASSES_BIAS)\n","\n","X_test = tokenize_testdata(X_test)\n","y_test_bias = to_categorical(y_test_bias, num_classes=NUM_CLASSES_BIAS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lbuZbdofqfki","colab_type":"code","colab":{}},"source":["print(y_bias[:5])\n","print(reverse_to_categorical(y_bias[:5]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hGwfROWqp-0J","colab_type":"code","colab":{}},"source":["X_train, X_validate, y_train_bias, y_validate_bias = train_test_split(X, y_bias,\n","                                                            test_size=0.2,\n","                                                            random_state=12)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MWO0vh7SquDm","colab_type":"code","colab":{}},"source":["#and build the embedding layer\n","embedding_layer = load_embeddings(word_index, \n","                                  f'{DATASET_PATH}/glove.6B.{EMBEDDING_DIM}d.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NP9s2MkFarPL","colab_type":"text"},"source":["## Compile model"]},{"cell_type":"code","metadata":{"id":"b9kj_pF47lkQ","colab_type":"code","colab":{}},"source":["#put embedding layer into input of the model\n","sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32')\n","embedded_sequences = embedding_layer(sequence_input)\n","\n","model = LSTM_model(sequence_input, embedded_sequences, classes=NUM_CLASSES_BIAS)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adamax',\n","              metrics=['acc'])\n","\n","print(model.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NuMxM9AEeAlL","colab_type":"text"},"source":["## Fit model"]},{"cell_type":"code","metadata":{"id":"MA04B9dGUDCR","colab_type":"code","colab":{}},"source":["model.fit(X_train, y_train_bias,\n","          validation_data=(X_validate, y_validate_bias),\n","          epochs=25,\n","          batch_size=250)\n","\n","y_pred_bias_validate = model.predict(X_validate)\n","print(classification_report(np.argmax(y_validate_bias, axis=1),\n","                            np.argmax(y_pred_bias_validate, axis=1),\n","                            target_names=['unbiased','biased']))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"95wb-IPQeFri","colab_type":"text"},"source":["## Predict"]},{"cell_type":"code","metadata":{"id":"lt3b-QFS9Orr","colab_type":"code","colab":{}},"source":["y_pred_bias = model.predict(X_test)\n","print(y_test_bias[:5])\n","print(y_pred_bias[:5])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VbEEc7BFIJc5","colab_type":"code","colab":{}},"source":["print(classification_report(np.argmax(y_test_bias, axis=1),\n","                            np.argmax(y_pred_bias, axis=1),\n","                            target_names=['unbiased','biased']))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"myTsQT2H7TtA","colab_type":"code","colab":{}},"source":["ax= plt.subplot()\n","cm = confusion_matrix(np.argmax(y_test_bias, axis=1), np.argmax(y_pred_bias, axis=1))\n","sns.heatmap(cm, annot=True, ax=ax, fmt='g')\n","ax.set_xlabel('Predicted')\n","ax.set_ylabel('True')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WgNWJzTweHwW","colab_type":"text"},"source":["## Save model"]},{"cell_type":"code","metadata":{"id":"YSOUWDIk5miv","colab_type":"code","colab":{}},"source":["model.save('lstm_binary.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yGgALKAgVOOE","colab_type":"text"},"source":["# Multiclass classifier (Kind of bias classifier)"]},{"cell_type":"markdown","metadata":{"id":"E3Y5zmNQV4oM","colab_type":"text"},"source":["## Separate labels from features"]},{"cell_type":"code","metadata":{"id":"NhbRbvRRWKdU","colab_type":"code","colab":{}},"source":["print(y_bias_kind[:5])\n","print(y_test_bias_kind[:5])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cc-STJ6aV-cj","colab_type":"text"},"source":["## Encode labels"]},{"cell_type":"code","metadata":{"id":"VR3trLUyg2nd","colab_type":"code","colab":{}},"source":["labelEncoder = LabelEncoder()\n","labelEncoder.fit(np.unique(y_bias_kind))\n","labelEncoder.classes_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jmmPZ6JmhxNo","colab_type":"code","colab":{}},"source":["y_bias_kind=labelEncoder.transform(y_bias_kind)\n","y_test_bias_kind=labelEncoder.transform(y_test_bias_kind)\n","\n","print(y_bias_kind[:5])\n","print(y_test_bias_kind[:5])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Azygqua6irm0","colab_type":"code","colab":{}},"source":["# Inverse tranform labels\n","labelEncoder.inverse_transform(y_bias_kind)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-590a-RCY_cP","colab":{}},"source":["y_bias_kind = to_categorical(y_bias_kind, num_classes=NUM_CLASSES_BIAS_KIND)\n","y_test_bias_kind = to_categorical(y_test_bias_kind, num_classes=NUM_CLASSES_BIAS_KIND)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rl__HQSei9pb","colab_type":"code","colab":{}},"source":["y_bias_kind[:5]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B97TTyIgjPKf","colab_type":"code","colab":{}},"source":["# TO get Reverse of to_categorical\n","print(reverse_to_categorical(y_bias_kind))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QeYoqSn5oFi0","colab_type":"text"},"source":["## Split into train and validate sets"]},{"cell_type":"code","metadata":{"id":"dT7bNqdGVq4M","colab_type":"code","colab":{}},"source":["X_train, X_validate, y_train_bias_kind, y_validate_bias_kind = train_test_split(X,\n","                                                            y_bias_kind,\n","                                                            test_size=0.2,\n","                                                            random_state=12)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bVOEY_KUZkvy","colab_type":"text"},"source":["## Compile model"]},{"cell_type":"code","metadata":{"id":"L1gm6L9xVqoI","colab_type":"code","colab":{}},"source":["#put embedding layer into input of the model\n","sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32')\n","embedded_sequences = embedding_layer(sequence_input)\n","\n","model = LSTM_model(sequence_input, embedded_sequences, classes=NUM_CLASSES_BIAS_KIND)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adamax',\n","              metrics=['acc'])\n","\n","print(model.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-kQZ-T0UeXju"},"source":["## Fit model"]},{"cell_type":"code","metadata":{"id":"Ml_a0AQ-Znvp","colab_type":"code","colab":{}},"source":["model.fit(X_train, y_train_bias_kind,\n","          validation_data=(X_validate, y_validate_bias_kind),\n","          epochs=25,\n","          batch_size=64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q2WnE5EFQK20","colab_type":"code","colab":{}},"source":["y_pred_bias_kind_validate = model.predict(X_validate)\n","print(classification_report(np.argmax(y_validate_bias_kind, axis=1),\n","                            np.argmax(y_pred_bias_kind_validate, axis=1),\n","                            target_names=labelEncoder.inverse_transform(reverse_to_categorical(y_train_bias_kind))))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y6YBqhn3emXm"},"source":["## Predict"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sVDX7WmGemXw","colab":{}},"source":["y_pred_bias_kind = model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"14Mle6kntIGw","colab_type":"code","colab":{}},"source":["y_test_bias_kind[:5]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZ5lTdZ2s_cI","colab_type":"code","colab":{}},"source":["y_pred_bias_kind[:5]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I9bcaMHRy1Ba","colab_type":"code","colab":{}},"source":["ax= plt.subplot()\n","cm = confusion_matrix(np.argmax(y_test_bias_kind, axis=1), np.argmax(y_pred_bias_kind, axis=1))\n","sns.heatmap(cm, annot=True, ax=ax, fmt='g')\n","ax.set_xlabel('Predicted')\n","ax.set_ylabel('True') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttNGWcFEM4Jv","colab_type":"code","colab":{}},"source":["print(classification_report(np.argmax(y_test_bias_kind, axis=1),\n","                            np.argmax(y_pred_bias_kind, axis=1),\n","                            target_names=labelEncoder.inverse_transform(reverse_to_categorical(y_train_bias_kind))))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RiMBSIhOesij"},"source":["## Save model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1AzbU835esis","colab":{}},"source":["model.save('lstm_multiclass.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z0sHfV3YVeC3","colab_type":"text"},"source":["# Multitask learning \n"," - task 1: biased/unbiased (binary)\n"," - task 2: kind of bias (multiclass)"]},{"cell_type":"code","metadata":{"id":"Szi64I0ZVks2","colab_type":"code","colab":{}},"source":["#put embedding layer into input of the model\n","input_layer = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32')\n","embed_layer = embedding_layer(input_layer)\n","\n","x = CuDNNLSTM(32, return_sequences=True)(embed_layer)\n","x = CuDNNLSTM(64, return_sequences=True)(x)\n","x = CuDNNLSTM(128)(x)\n","x = Dense(4096, activation='relu')(x)\n","x = Dense(1024, activation='relu')(x)\n","\n","# task 1\n","output_bias = Dense(2, activation='softmax')(x)\n","\n","# task 2\n","output_bias_kind = Dense(5, activation='softmax')(x)\n","\n","model = Model(input_layer, [output_bias, output_bias_kind])\n","\n","model.compile(loss='categorical_crossentropy', \n","              optimizer='adamax', \n","              metrics=['acc'])\n","\n","print(model.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KsvEjAi8efcv"},"source":["## Fit model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7Z7Bb0Gwefc4","colab":{}},"source":["model.fit(X_train, [y_train_bias, y_train_bias_kind] ,\n","          validation_data=(X_validate, [y_validate_bias, y_validate_bias_kind]),\n","          epochs=50,\n","          batch_size=64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tzSf-GgR17O","colab_type":"code","colab":{}},"source":["y_pred_bias_validate, y_pred_bias_kind_validate = model.predict(X_validate)\n","\n","print(classification_report(np.argmax(y_validate_bias, axis=1),\n","                            np.argmax(y_pred_bias_validate, axis=1),\n","                            target_names=['unbiased','biased']))\n","\n","print(classification_report(np.argmax(y_validate_bias_kind, axis=1),\n","                            np.argmax(y_pred_bias_kind_validate, axis=1),\n","                            target_names=labelEncoder.inverse_transform(reverse_to_categorical(y_train_bias_kind))))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Y8S_J548e3LV"},"source":["## Predict"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HguHhvJ0e3LY","colab":{}},"source":["y_pred_bias, y_pred_bias_kind = model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bNSDi3kBSl2f","colab_type":"code","colab":{}},"source":["print(classification_report(np.argmax(y_test_bias, axis=1),\n","                            np.argmax(y_pred_bias, axis=1),\n","                            target_names=['unbiased','biased']))\n","\n","print(classification_report(np.argmax(y_test_bias_kind, axis=1),\n","                            np.argmax(y_pred_bias_kind, axis=1),\n","                            target_names=labelEncoder.inverse_transform(reverse_to_categorical(y_train_bias_kind))))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"znCed-13VmIW","colab_type":"code","colab":{}},"source":["ax= plt.subplot()\n","cm = confusion_matrix(np.argmax(y_test_bias, axis=1), np.argmax(y_pred_bias, axis=1))\n","sns.heatmap(cm, annot=True, ax=ax, fmt='g')\n","ax.set_xlabel('Predicted')\n","ax.set_ylabel('True') \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ciRLrqIuVZoH","colab_type":"code","colab":{}},"source":["ax= plt.subplot()\n","cm = confusion_matrix(np.argmax(y_test_bias_kind, axis=1), np.argmax(y_pred_bias_kind, axis=1))\n","sns.heatmap(cm, annot=True, ax=ax, fmt='g')\n","ax.set_xlabel('Predicted')\n","ax.set_ylabel('True') "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mVqkbeGBevxM"},"source":["## Save model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5_fojL4JevxU","colab":{}},"source":["model.save('lstm_multitask.h5')"],"execution_count":0,"outputs":[]}]}