{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Multitask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjVgGSszsE86",
        "colab_type": "text"
      },
      "source": [
        "# CuDNNLSTM() trains faster but does not allow Dropout() \n",
        "# so falling back to LSTM() adding dropout layers we achieved validation accuracy of 93%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apoTJfS7Wa3U",
        "colab_type": "code",
        "outputId": "7bc6dba0-720a-4157-d8e7-60531ae08072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUNKZFJBWfVC",
        "colab_type": "code",
        "outputId": "5d205de9-f6f3-4226-addd-29915e70cd77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "DATASET_PATH = \"/content/drive/My Drive/ire-proj/processedData\"\n",
        "!ls \"$DATASET_PATH\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "articles-training-byarticle.csv        articles-validation-bypublisher.csv\n",
            "articles-training-bypublisher.csv      glove.6B.300d.txt\n",
            "articles-training-bypublisher-old.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1E3dl4Aw8NK",
        "colab_type": "code",
        "outputId": "46c60178-fe02-454d-f05c-ed2fcfcb073f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras import Sequential, Model, Input\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Flatten, Dense, \\\n",
        "                    GlobalAveragePooling1D, Dropout, LSTM, CuDNNLSTM, RNN, SimpleRNN, Conv2D, GlobalMaxPooling1D\n",
        "from keras import callbacks\n",
        "\n",
        "import re\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "import pickle\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from numpy.testing import assert_allclose"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXRZjhyQPwnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_TRAINING_SAMPLES = None\n",
        "\n",
        "N_TEST_SAMPLES = N_TRAINING_SAMPLES // 2 if N_TRAINING_SAMPLES is not None else None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMWNO_G6ZG1c",
        "colab_type": "text"
      },
      "source": [
        "# Preparing text data\n",
        "Format text samples and labels into tensors that can be fed into a neural network.\n",
        "- keras.preprocessing.text.Tokenizer\n",
        "- keras.preprocessing.sequence.pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkzzVVf6Z-fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source: https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
        "\n",
        "MAX_NUM_WORDS = 50000    # dictionary size\n",
        "MAX_SEQUENCE_LENGTH = 1500  # max word length of each individual article\n",
        "EMBEDDING_DIM = 300 # dimensionality of the embedding vector (50, 100, 200, 300)\n",
        "\n",
        "TOKENIZER_DUMP_FILE='tokenizer.p'\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS,\n",
        "                      filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~')\n",
        "\n",
        "def tokenize_trainingdata(X):\n",
        "    tokenizer.fit_on_texts(X)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    print(f'Found {len(word_index)} unique tokens.')\n",
        "\n",
        "    X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "    with open(TOKENIZER_DUMP_FILE, 'wb') as fp:\n",
        "        pickle.dump(tokenizer, fp)\n",
        "\n",
        "    return X, word_index\n",
        "\n",
        "def tokenize_testdata(X):\n",
        "    with open(TOKENIZER_DUMP_FILE, 'rb') as fp:\n",
        "        tokenizer=pickle.load(fp)\n",
        "\n",
        "    print(f'Found {len(tokenizer.word_index)} unique tokens.')\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "    X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYgT0kdTk4v7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reverse_to_categorical(y):\n",
        "    return np.argmax(y[:5], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V94j5Z5YYett",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQcYYZNlZx3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_embeddings(word_index, GLOVE_FILE_PATH):\n",
        "    # Load glove word embeddings\n",
        "    embeddings_index = {}\n",
        "    f = open(GLOVE_FILE_PATH, 'r', encoding='utf8')\n",
        "    for line in f:\n",
        "        # each line starts with a word; rest of the line is the vector\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    print(f'Found {len(embeddings_index)} word vectors in glove file.')\n",
        "\n",
        "    # Now use embedding_index dictionary and our word_index \n",
        "    # to compute our embedding matrix\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    print(\"embedding_matrix shape:\", np.shape(embedding_matrix))\n",
        "\n",
        "    # load pre-trained word embeddings into an Embedding layer\n",
        "    # note that we set trainable = False so as to keep the embeddings fixed\n",
        "    embedding_layer = Embedding(len(word_index) + 1,\n",
        "                                EMBEDDING_DIM,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=False)\n",
        "    return embedding_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbXNIWXRUvFY",
        "colab_type": "text"
      },
      "source": [
        "# Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5SNgt_R4gBr",
        "colab_type": "code",
        "outputId": "7efd7eb8-50c3-4a4d-bad7-fb30784dd344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df = pd.read_csv(filepath_or_buffer= DATASET_PATH + '/articles-training-bypublisher.csv',\n",
        "                 names=['article_id', 'title', 'articleContent', 'bias', 'hyperpartisan'],\n",
        "                 dtype={'title':str},\n",
        "                 nrows=N_TRAINING_SAMPLES)\n",
        "\n",
        "df['title'] = df['title'].fillna(value=' ')\n",
        "df.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "article_id        600000\n",
              "title             600000\n",
              "articleContent    600000\n",
              "bias              600000\n",
              "hyperpartisan     600000\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXlIpKD_FaZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perform_cleaning(text):\n",
        "    text = text.lower().strip()\n",
        "    text = ' '.join(e for e in text.split())\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
        "    return text\n",
        "\n",
        "df['title'] = df['title'].map(perform_cleaning)\n",
        "df['articleContent'] = df['articleContent'].map(perform_cleaning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFJdEBdT_dv5",
        "colab_type": "code",
        "outputId": "f81f5dee-c40b-49fe-e0c0-c0cbdfd57aa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()\n",
        "# df.tail(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>title</th>\n",
              "      <th>articleContent</th>\n",
              "      <th>bias</th>\n",
              "      <th>hyperpartisan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>after devos announced plans to reexamine title...</td>\n",
              "      <td>when explaining her decision to reevaluate tit...</td>\n",
              "      <td>right</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>university to award trayvon martin with posthu...</td>\n",
              "      <td>a florida university will honor trayvon martin...</td>\n",
              "      <td>right</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>texas state university suspends greek life aft...</td>\n",
              "      <td>nov 15 upi texas state university has suspende...</td>\n",
              "      <td>right-center</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>jewish organization s huge day of unity on tue...</td>\n",
              "      <td>against the backdrop of an increasingly polari...</td>\n",
              "      <td>right</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>breaking trump reaches agreement to keep 1 000...</td>\n",
              "      <td>president elect donald trump has reached an ag...</td>\n",
              "      <td>right</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   article_id  ... hyperpartisan\n",
              "0           1  ...          True\n",
              "1           2  ...          True\n",
              "2           8  ...         False\n",
              "3          12  ...          True\n",
              "4          15  ...          True\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-w5jRnRPrEL",
        "colab_type": "code",
        "outputId": "409e154d-5ff9-4bdf-dc04-acf0c022ca6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df_test = pd.read_csv(filepath_or_buffer=DATASET_PATH + '/articles-validation-bypublisher.csv',\n",
        "                 names=['article_id', 'title', 'articleContent', 'bias', 'hyperpartisan'],\n",
        "                 nrows=N_TEST_SAMPLES\n",
        "                 )\n",
        "df_test['title'] = df_test['title'].fillna(value=' ')\n",
        "df_test.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "article_id        150000\n",
              "title             150000\n",
              "articleContent    150000\n",
              "bias              150000\n",
              "hyperpartisan     150000\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD8n2FOJQPhq",
        "colab_type": "code",
        "outputId": "ff462c92-436e-41bc-f92d-5e0ca554b8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_test['title'] = df_test['title'].map(perform_cleaning)\n",
        "df_test['articleContent'] = df_test['articleContent'].map(perform_cleaning)\n",
        "df_test.tail(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>title</th>\n",
              "      <th>articleContent</th>\n",
              "      <th>bias</th>\n",
              "      <th>hyperpartisan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>149995</th>\n",
              "      <td>1494825</td>\n",
              "      <td></td>\n",
              "      <td>by andrew osborn moscow reuters russia is quie...</td>\n",
              "      <td>left</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149996</th>\n",
              "      <td>1494857</td>\n",
              "      <td>i now pronounce you spouse and spouse</td>\n",
              "      <td>in keeping with its reputation of pioneering s...</td>\n",
              "      <td>right</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149997</th>\n",
              "      <td>1494877</td>\n",
              "      <td>it s now clear that only a democrat can stop d...</td>\n",
              "      <td>donald trump s ongoing evisceration of the rep...</td>\n",
              "      <td>left</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149998</th>\n",
              "      <td>1494883</td>\n",
              "      <td>the liberal redneck my proudest moment as a de...</td>\n",
              "      <td>lr the liberal redneck here coming to you afte...</td>\n",
              "      <td>left</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149999</th>\n",
              "      <td>1494893</td>\n",
              "      <td>obama s victory fourth global press roundup</td>\n",
              "      <td>from watching america com here s another delug...</td>\n",
              "      <td>least</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        article_id  ... hyperpartisan\n",
              "149995     1494825  ...          True\n",
              "149996     1494857  ...          True\n",
              "149997     1494877  ...          True\n",
              "149998     1494883  ...          True\n",
              "149999     1494893  ...         False\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JgTxNAt4j7s",
        "colab_type": "code",
        "outputId": "a67852de-5c16-4655-b875-b02845994164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(df['hyperpartisan'].value_counts())\n",
        "print(df_test['hyperpartisan'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True     300000\n",
            "False    300000\n",
            "Name: hyperpartisan, dtype: int64\n",
            "True     75000\n",
            "False    75000\n",
            "Name: hyperpartisan, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwq0eV4tVUHQ",
        "colab_type": "text"
      },
      "source": [
        "# Binary classifier (Biased / Unbiased)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SjppIvA1bMYF"
      },
      "source": [
        "## Separate labels from features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3wED1DTtbMYM",
        "colab": {}
      },
      "source": [
        "X = df.articleContent.values\n",
        "y_bias = df.hyperpartisan.values\n",
        "y_bias_kind = df.bias.values\n",
        "\n",
        "X_test = df_test.articleContent.values\n",
        "y_test_bias = df_test.hyperpartisan.values\n",
        "y_test_bias_kind = df_test.bias.values\n",
        "\n",
        "NUM_CLASSES_BIAS = len(np.unique(y_bias))\n",
        "NUM_CLASSES_BIAS_KIND = len(np.unique(y_bias_kind))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nRJiV-XXbMYY",
        "outputId": "ee7711ce-6e9c-4588-c530-da540257280d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(y_bias[:5])\n",
        "print(y_bias_kind[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True False  True  True]\n",
            "['right' 'right' 'right-center' 'right' 'right']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCALMavEaeA6",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSq4NaWO5UFK",
        "colab_type": "code",
        "outputId": "b95e9d75-6b61-4951-e53b-3c6a0894cace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X, word_index = tokenize_trainingdata(X)\n",
        "y_bias = to_categorical(y_bias, num_classes=NUM_CLASSES_BIAS)\n",
        "\n",
        "X_test = tokenize_testdata(X_test)\n",
        "y_test_bias = to_categorical(y_test_bias, num_classes=NUM_CLASSES_BIAS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 700689 unique tokens.\n",
            "Found 700689 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbuZbdofqfki",
        "colab_type": "code",
        "outputId": "0a4dbfaf-aa59-4945-f8d7-a3bea2c2008b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(y_bias[:5])\n",
        "print(reverse_to_categorical(y_bias[:5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "[1 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGwfROWqp-0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_validate, y_train_bias, y_validate_bias = train_test_split(X, y_bias,\n",
        "                                                            test_size=0.2,\n",
        "                                                            random_state=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP9s2MkFarPL",
        "colab_type": "text"
      },
      "source": [
        "## Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hffbip0qj7SN",
        "colab_type": "code",
        "outputId": "847f0532-217e-4a22-c102-df8ccb6fa226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "loaded_embeddings = load_embeddings(word_index, \n",
        "                                  f'{DATASET_PATH}/glove.6B.{EMBEDDING_DIM}d.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors in glove file.\n",
            "embedding_matrix shape: (700690, 300)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6t9q10grVMQ",
        "colab_type": "code",
        "outputId": "d12e02bb-fd1f-4eca-a8f5-aaade4ce5417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "input_layer = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32')\n",
        "\n",
        "embedding_layer = loaded_embeddings(input_layer)\n",
        "embedding_layer = Dropout(0.5)(embedding_layer)\n",
        "\n",
        "hidden_layer = LSTM(64, recurrent_dropout=0.5)(embedding_layer)\n",
        "hidden_layer = Dropout(0.5)(hidden_layer)\n",
        "output_layer = Dense(2, activation='softmax')(hidden_layer)\n",
        "\n",
        "model = Model(input_layer, output_layer)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adamax',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1500)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 1500, 300)         210207000 \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1500, 300)         0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 210,300,570\n",
            "Trainable params: 93,570\n",
            "Non-trainable params: 210,207,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuMxM9AEeAlL",
        "colab_type": "text"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOq5jMExP8AC",
        "colab_type": "code",
        "outputId": "68e47712-32a1-40b4-a68f-8dbf78b98de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "CHECKPOINT_FILE = 'partial_lstm_binary.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(CHECKPOINT_FILE, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "new_model = None\n",
        "\n",
        "model.fit(X_train, y_train_bias,\n",
        "              validation_data=(X_validate, y_validate_bias),\n",
        "              epochs=25, batch_size=250,\n",
        "              callbacks=callbacks_list)\n",
        "    \n",
        "# new_model = load_model(CHECKPOINT_FILE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 480000 samples, validate on 120000 samples\n",
            "Epoch 1/25\n",
            "480000/480000 [==============================] - 5023s 10ms/step - loss: 0.4874 - acc: 0.7503 - val_loss: 0.4052 - val_acc: 0.8036\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.48739, saving model to partial_lstm_binary.h5\n",
            "Epoch 2/25\n",
            "418000/480000 [=========================>....] - ETA: 10:00 - loss: 0.4367 - acc: 0.7869"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA04B9dGUDCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_bias_validate = model.predict(X_validate)\n",
        "print(classification_report(np.argmax(y_validate_bias, axis=1),\n",
        "                            np.argmax(y_pred_bias_validate, axis=1),\n",
        "                            target_names=['unbiased','biased']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95wb-IPQeFri",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt3b-QFS9Orr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_bias = model.predict(X_test)\n",
        "print(y_test_bias[:5])\n",
        "print(y_pred_bias[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbEEc7BFIJc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(np.argmax(y_test_bias, axis=1),\n",
        "                            np.argmax(y_pred_bias, axis=1),\n",
        "                            target_names=['unbiased','biased']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myTsQT2H7TtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax= plt.subplot()\n",
        "cm = confusion_matrix(np.argmax(y_test_bias, axis=1), np.argmax(y_pred_bias, axis=1))\n",
        "sns.heatmap(cm, annot=True, ax=ax, fmt='g')\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('True')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgNWJzTweHwW",
        "colab_type": "text"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSOUWDIk5miv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('lstm_binary.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGgALKAgVOOE",
        "colab_type": "text"
      },
      "source": [
        "# Multiclass classifier (Kind of bias classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3Y5zmNQV4oM",
        "colab_type": "text"
      },
      "source": [
        "## Separate labels from features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhbRbvRRWKdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_bias_kind[:5])\n",
        "print(y_test_bias_kind[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc-STJ6aV-cj",
        "colab_type": "text"
      },
      "source": [
        "## Encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR3trLUyg2nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelEncoder = LabelEncoder()\n",
        "labelEncoder.fit(np.unique(y_bias_kind))\n",
        "labelEncoder.classes_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmmPZ6JmhxNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_bias_kind=labelEncoder.transform(y_bias_kind)\n",
        "y_test_bias_kind=labelEncoder.transform(y_test_bias_kind)\n",
        "\n",
        "print(y_bias_kind[:5])\n",
        "print(y_test_bias_kind[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azygqua6irm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inverse tranform labels\n",
        "labelEncoder.inverse_transform(y_bias_kind[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-590a-RCY_cP",
        "colab": {}
      },
      "source": [
        "y_bias_kind = to_categorical(y_bias_kind, num_classes=NUM_CLASSES_BIAS_KIND)\n",
        "y_test_bias_kind = to_categorical(y_test_bias_kind, num_classes=NUM_CLASSES_BIAS_KIND)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl__HQSei9pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_bias_kind[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B97TTyIgjPKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO get Reverse of to_categorical\n",
        "print(reverse_to_categorical(y_bias_kind))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeYoqSn5oFi0",
        "colab_type": "text"
      },
      "source": [
        "## Split into train and validate sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT7bNqdGVq4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_validate, y_train_bias_kind, y_validate_bias_kind = train_test_split(X,\n",
        "                                                            y_bias_kind,\n",
        "                                                            test_size=0.2,\n",
        "                                                            random_state=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVOEY_KUZkvy",
        "colab_type": "text"
      },
      "source": [
        "## Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5WrEtEItF6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32')\n",
        "\n",
        "embedding_layer = loaded_embeddings(input_layer)\n",
        "embedding_layer = Dropout(0.5)(embedding_layer)\n",
        "\n",
        "hidden_layer = LSTM(64, recurrent_dropout=0.5)(embedding_layer)\n",
        "hidden_layer = Dropout(0.5)(hidden_layer)\n",
        "output_layer = Dense(NUM_CLASSES_BIAS_KIND, activation='softmax')(hidden_layer)\n",
        "\n",
        "model = Model(input_layer, output_layer)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adamax',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-kQZ-T0UeXju"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iTU_XD6t5l9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CHECKPOINT_FILE = 'partial_lstm_multiclass.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(CHECKPOINT_FILE, monitor='loss', verbose=1, \n",
        "                             save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model.fit(X_train, y_train_bias_kind,\n",
        "              validation_data=(X_validate, y_validate_bias_kind),\n",
        "              epochs=25, batch_size=250,\n",
        "              callbacks=callbacks_list)\n",
        "\n",
        "# new_model = load_model(CHECKPOINT_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2WnE5EFQK20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_bias_kind_validate = model.predict(X_validate)\n",
        "print(classification_report(np.argmax(y_validate_bias_kind, axis=1),\n",
        "                            np.argmax(y_pred_bias_kind_validate, axis=1),\n",
        "                            target_names=labelEncoder.inverse_transform(reverse_to_categorical(y_train_bias_kind))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y6YBqhn3emXm"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sVDX7WmGemXw",
        "colab": {}
      },
      "source": [
        "y_pred_bias_kind = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Mle6kntIGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_bias_kind[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ5lTdZ2s_cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_bias_kind[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9bcaMHRy1Ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax= plt.subplot()\n",
        "cm = confusion_matrix(np.argmax(y_test_bias_kind, axis=1), np.argmax(y_pred_bias_kind, axis=1))\n",
        "sns.heatmap(cm, annot=True, ax=ax, fmt='g')\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('True') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttNGWcFEM4Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(np.argmax(y_test_bias_kind, axis=1),\n",
        "                            np.argmax(y_pred_bias_kind, axis=1),\n",
        "                            target_names=labelEncoder.inverse_transform(reverse_to_categorical(y_train_bias_kind))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RiMBSIhOesij"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1AzbU835esis",
        "colab": {}
      },
      "source": [
        "model.save('lstm_multiclass.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0sHfV3YVeC3",
        "colab_type": "text"
      },
      "source": [
        "# Multitask learning \n",
        " - task 1: biased/unbiased (binary)\n",
        " - task 2: kind of bias (multiclass)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j6mMPbhuQuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32')\n",
        "\n",
        "embedding_layer = loaded_embeddings(input_layer)\n",
        "embedding_layer = Dropout(0.5)(embedding_layer)\n",
        "\n",
        "hidden_layer = LSTM(64, recurrent_dropout=0.5)(embedding_layer)\n",
        "hidden_layer = Dropout(0.5)(hidden_layer)\n",
        "\n",
        "# task 1\n",
        "output_bias = Dense(2, activation='softmax')(hidden_layer)\n",
        "\n",
        "# task 2\n",
        "output_bias_kind = Dense(5, activation='softmax')(hidden_layer)\n",
        "\n",
        "\n",
        "model = Model(input_layer, [output_bias, output_bias_kind])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adamax', \n",
        "              metrics=['acc'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KsvEjAi8efcv"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nvfx6PovA65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CHECKPOINT_FILE = 'partial_lstm_multitask.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(CHECKPOINT_FILE, monitor='loss', verbose=1,\n",
        "                             save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model.fit(X_train, [y_train_bias, y_train_bias_kind],\n",
        "              validation_data=(X_validate, [y_validate_bias, y_validate_bias_kind]),\n",
        "              epochs=25, batch_size=250,\n",
        "              callbacks=callbacks_list)\n",
        "\n",
        "# model = load_model(CHECKPOINT_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tzSf-GgR17O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_bias_validate, y_pred_bias_kind_validate = model.predict(X_validate)\n",
        "\n",
        "print(classification_report(np.argmax(y_validate_bias, axis=1),\n",
        "                            np.argmax(y_pred_bias_validate, axis=1),\n",
        "                            target_names=['unbiased','biased']))\n",
        "\n",
        "print(classification_report(np.argmax(y_validate_bias_kind, axis=1),\n",
        "                            np.argmax(y_pred_bias_kind_validate, axis=1),\n",
        "                            target_names=labelEncoder.inverse_transform(reverse_to_categorical(y_train_bias_kind))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y8S_J548e3LV"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HguHhvJ0e3LY",
        "colab": {}
      },
      "source": [
        "y_pred_bias, y_pred_bias_kind = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNSDi3kBSl2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(np.argmax(y_test_bias, axis=1),\n",
        "                            np.argmax(y_pred_bias, axis=1),\n",
        "                            target_names=['unbiased','biased']))\n",
        "\n",
        "print(classification_report(np.argmax(y_test_bias_kind, axis=1),\n",
        "                            np.argmax(y_pred_bias_kind, axis=1),\n",
        "                            target_names=labelEncoder.inverse_transform(reverse_to_categorical(y_train_bias_kind))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znCed-13VmIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax= plt.subplot()\n",
        "cm = confusion_matrix(np.argmax(y_test_bias, axis=1), np.argmax(y_pred_bias, axis=1))\n",
        "sns.heatmap(cm, annot=True, ax=ax, fmt='g')\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('True') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciRLrqIuVZoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax= plt.subplot()\n",
        "cm = confusion_matrix(np.argmax(y_test_bias_kind, axis=1), np.argmax(y_pred_bias_kind, axis=1))\n",
        "sns.heatmap(cm, annot=True, ax=ax, fmt='g')\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('True') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mVqkbeGBevxM"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5_fojL4JevxU",
        "colab": {}
      },
      "source": [
        "model.save('lstm_multitask.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}